<<<
[[execute]]
== Vector Datapath

The vector datapath (VU) handles all vector instruction scheduling, computation, and register file access.
The VU is organized around independent "sequencing paths", which issue instructions independently to a per-sequencer vector execution unit (VXU).

The datapath is organized around a "vector element group" as the base unit of register access and compute.
An element group is a fixed-width `DLEN`-bits-wide contiguous slice of the architectural register file space.
`DLEN` guides the parameterization of most critical components in the backend.
The register file, load-path, store-path, and most functional units are designed to process DLEN bits per cycle (or 1 element group/cycle), regardless of element width (`ELEN`).

=== Issue Queues

Vector instructions entering the VU are immediately assigned a unique age tag and enqueued into an in-order dispatch queue (VDQ).
The age tag is used to disambiguate age for determining data hazards in the out-of-order sequencing stage.
This means the age tag is wide enough to assign a unique tag to every inflight operation in the backend.
Age tags are recovered when instructions complete execution.

The VDQ provides a low-cost decoupling queue between the VU and the VLSU.
The dequeue side of the VDQ is connected to the vector issue queues (VIQs).
Each VIQ issues instructions in-order into its corresponding instruction sequencer.
However, execution across the VIQs may be out-of-order, as the VIQs may naturally "slip" against each other.

Each sequencing path has an independent issue queue.
The load issue queue only needs to track a destination address and mask enable, while the store issue queue only needs to track a source address and mask enable.
The arithmetic issue queue(s) must track up to two source operands along with the destination and mask enable.
The permute issue queue, used for index generation and register gathers, tracks only a source operand.

There are three configuration options for the arithmetic issue queues.

[.text-center]
.Issue queue configurations
image::diag/iqconfigs.png[Issue queue configurations,width=900,align=center,title-align=center]


 * In the *unified* configuration, there is a single sequencer for all arithmetic operations fed by a VIQ. This configuration has the lowest hardware cost, but cannot simultaneously saturate integer and floating-point functional units.
 * In the *shared* configuration, there are separate integer and floating-point sequencers fed by a common VIQ.
 Instructions are issued from the shared VIQ to either the integer or floating-point sequencer.
 This configuration can simultaneously saturate integer and floating-point execution units with well-scheduled code.
 * In the *split* configuration, there are separate integer and floating-point sequencers that are each fed by an independent issue queue. This configuration is the most performant, as it can dynamically schedule out-of-order across integer and floating-point instructions, but is also the most costly, owing to the separate floating-point issue queue.

=== Operation Sequencers

[.text-center]
.Vector instruction sequencer
image::diag/sequencer.png[Instruction sequencer,width=900,align=center,title-align=center]

The instruction sequencers convert a vector instruction into a sequence of operations that execute down the functional unit datapaths, one operation per cycle.
The sequencers advertise the requested register file read and write addresses for the next operation, as well as the age tag for the currently sequenced instruction.
If there are no structural hazards from non-pipelined functional units or register file ports and there are no data hazards against older vector instructions, a sequencer will issue an operation and update its internal state.
An instruction will depart a sequencer along with the last operation it sequences, eliminating dead-time between successive vector instructions.

Notably, the sequencers enact "fire-and-forget" operation issue.
Once an operation is issued by a sequencer, it is guaranteed to be free of further structural or data hazards as it proceeds down the pipelined VFU datapaths.
This eliminates the need for costly back-pressured operand or result queues.

[discrete]
==== Load/Store Sequencers

The load-store sequencers are the simplest, as they only track one vector operand or destination.

The load sequencer sequences load writebacks into the VRF.
The load sequencer will stall if the decoupled load response port from the VLSU has not presented a requested element group of write-back data.
Since the VLSU's load path and the load-issue path are both in-order, issued operations from the sequencer pop the next element group from the decoupled load-response port and write into the VRF.

The store sequencer behaves similarly to the load sequencer, except it sequences element groups of data into the decoupled store-data port.
The store data-port can deassert ready to stall the store sequencer.

Both the load and store sequencers additionally handle the complex case of segmented operations, which write a set of consecutive vector registers.
To align with the data order expected in the segment buffers in the VLSU, the sequencers execute two nested loops to handle these instructions. The outer loop iterates over element group index, just as in normal vector instructions, while the inner loop iterates over the number of fields in the segmented instruction.

[discrete]
==== Execute Sequencer

The execute sequencers sequence all arithmetic operations.
They track up to three register operands, with up to four reads and one write per operation (for a masked FMA).
Each execute sequencer issues to a single vector execution unit (VXU).
A VXU is a collection of vector functional units (VFUs).
The execute sequencers will stall operation execution if the requested VFU within its VXU is unavailable.

The execute sequencers additionally contain a DLEN-wide accumulation register for vector reductions.
Vector reductions will accumulate into this register iteratively before generating a final writeback into the VRF.

[discrete]
==== Permute Sequencer

The permute sequencer handles index generation for register-gather and indexed-memory operations.
For memory operations, it sequences into the index-port to the VLSU.
For register-gather operations, it sequences register reads into an index queue that feeds the arithmetic sequencer for register gathers.
For slides, the index queue is reused to align the slide operand to the result. In other words, the register-read for slides is performed by the permute sequencer, while the writeback is sequenced by the integer arithmetic sequencer.

=== Hazards

Due to the out-of-order execution across the different sequences, RAW, WAW and WAR hazards are all possible.
Furthermore, supporting vector chaining implies that these hazards should be resolved at sub-vector-register granularity.
Since Saturn is designed around `DLEN`-wide element groups as the core unit of compute, Saturn resolves data hazards at `DLEN` granularity.
The scheduling mechanism precisely tracks which element groups an instruction or operation is yet-to-read-or-write to interlock the sequencers.

In Saturn, the "out-of-order instruction window" includes all instructions in the issue queues (but not the VDQ), the instructions currently in progress within the sequencers, and any operations which have not yet completed execution in the functional unit datapaths.
All instructions in this window must advertise a precise set of element groups they have not yet read or written, along with the age tag of the instruction.

 * Instructions in the issue queues already contain their operand specifiers. Since these instructions have not yet been sequenced, a conservative bound on the element groups to be accessed can be easily computed using the `LMUL` and the base register operand.
 * The sequencers track a precise bit-vector of element groups that the currently-sequenced instruction may still access. For regular vector instructions that access their operands sequentially, the sequencers can clear these bits with each issued operation. For irregular vector instructions, the sequencers can conservatively leave these bits set.
 * Operations in the functional unit that have yet to write back track a single element group of the write destination.

The advertised information across the out-of-order window is aggregated into a pending-read and pending-write one-hot vector for each sequencer.
These one-hot vectors each contain one element for each architectural element group in the VRF, which is 32xVLEN/DLEN.
These one-hot vectors are constructed using an age filter based on the age tag of the current instruction in the sequencer along with the age of each operation in the out-of-order window.
The age filter restricts the pending-read and pending-write tables to only contain pending reads and writes from instructions older than the currently sequenced instruction.

In some cases, the relative age is unambiguous, so no age filter is needed.
Instructions in the sequencer are inherently older than instructions from the feeding issue queue for that sequencer, so no age filter is needed.
Sequenced operations in the VFUs are inherently the oldest writes to any element group, so no age filter is needed for these either.

Each sequencer computes the element groups that will be accessed or written to by the next operation to be issued, and determines if a pending older read or write to those element groups would induce a RAW, WAR or WAR hazard.
If there is no data hazard and there is no structural hazard, the operation can be issued, with the sequencer incrementing its internal element index counter, or draining the instruction.

For vector instructions with regular consecutive access patterns, the last issued operation that accesses some element group can clear the sequencer's internal bit-vector of pending reads and/or writes.
This frees younger vector instructions in other sequencers to chain off this element group as soon as possible.

=== Vector Register File

The VRF is organized as a multi-ported banked array of flops.
The architectural register file is striped across the banks by element group index.
Neighboring element groups reside in neighboring banks.
Each bank contains 3 read ports and 1 write port, to fulfill the minimum read requirements of a three-input fused-multiply-add.
The generator supports generating VRFs with 1, 2, or 4 banks.
Configurations that expect to keep multiple integer sequencers utilized simultaneously will prefer more banks to meet the increased read bandwidth requirements.

A shadow copy of  vector mask register `v0` is maintained in a 1R1W memory to avoid provisioning an extra read port for the bulk banked register file.

A read crossbar connects the issue port of the sequencers to the register file read ports.
The read crossbar resolves structural hazards during the read stage and stalls the sequencers if necessary.
The read stage also arbitrates for access to the write ports across multiple fixed-latency execution paths.

=== Functional Units

Each execution unit is composed of some set of functional units.
Operations are issued to functional units along with their vector operands.
Functional units can either be pipelined or iterative.

Pipelined functional units have fixed execution latencies, so once an operation is issued, it will execute without stalling.
The sequencing mechanism checks for future write port conflicts on the target VRF bank across inflight and simultaneously sequenced operations to ensure that the next sequenced operation will not induce a structural hazard on the write port in the future.
If a conflict is detected, the younger operation will be stalled and will likely start executing the very next cycle.

Iterative functional units have variable execution latencies or contain expensive hardware such that it is desirable to execute at a rate of just one element per cycle.
Once an iterative functional unit has completed its operation on a given element, it will arbitrate for the target VRF write port, write the result, then assert readiness to accept a new operation from the sequencer.

[cols="1,2,2,2,3"]
|===
|Name|Instruction support|Microarchitecture/s|Structure|Notes

|ALU
|Integer add/sub/max/min
|SIMD-array of ALUs
|1-stage pipeline
|

|ISU
|Shift instructions
|SIMD-array of barrel-shifters
|2-stage pipeline
|

|BWU
|Bitwise operations
|Bitwise array
|1-stage pipeline
|

|IDU
|Integer divide (opt. multiply)
|Iterative FSM
|Iterative-elementwise
|Can also support integer-multiply in area-minimal configurations

.2+|IMU
.2+|Integer multiply
|Single elementwise multiplier
.2+|3-stage pipeline
.2+|For area-minimal configurations, avoid building the SIMD array

|SIMD array of multipliers

|PMU
|Slides, gathers, compress
|Minimal logic
|1-stage pipeline
|Generates the writebacks for its instructions

|PFU
|Prefix-like instructions (popc/first/sbf/iota/etc.)
|Prefix-sum circuit with accumulator
|1-stage pipeline
|

.2+|FMA
.2+|Floating-point multiply/adds
|Port to host CPU's FPU
.2+|4-stage pipeline
.2+|For area-minimal vector units, share the FPU with the host CPU

|SIMD array of FMAs

|FDU
|Floating-point divide, square-root
|Single iterative unit
|Iterative-elementwise
|

|FCU
|Floating-point convert/compare
|SIMD array of FP units
|1-stage pipeline
|

|===

For slide and register-gather instructions, a separate permute-sequencer reads out the source operand for slides, and index operand for register-gather.
These operands enter a permute-buffer, which is read by the main arithmetic sequencer to generate aligned operands for slides, and read addresses for register-gathers.


// === EVA (Extended Vector Architecture) Port

// The EVA port provides an interface for integrating the Saturn vector unit with custom accelerators or functional units.
// Physically, this interface appears allows users to integrate a custom functional unit accepting some subset of the empty RVV encoding space.
// Like all other functional units, a EVA-attached functional unit must advertise the pending reads or writes a current in-flight operations will make into the VRF.
// This allows Saturn's instruction sequencers to schedule EVA instructions alongside standard vector instructions, and enables chaining to and from EVA instructions.

// A EVA accelerator implementation should additionally be parameterized by `VLEN` and `DLEN`, to match the range of possible Saturn configurations it may be attached to.

// The EVA interface is a port that exposes data read from the VRF along with control signals, and can take in data from the external unit and write it into the VRF.
// A key idea of the EVA interface is that it enables Saturn to execute custom instructions that specify VRF sources and destinations just like standard vector instructions.
// This allows Saturn to sequence these instructions alongside standard vector instructions, using very similar mechanisms.
// This enables the external accelerator or functional unit to utilize the Saturn vector unit as a base of compute and communicate with it over a high-bandwidth interface.

// TODO add more details
